{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbPugxQ_yOG4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'id': [1, 2, 2, 3, 4, 4],\n",
        "    'name': ['Alice', 'Bob', 'Bob', 'Charlie', 'David', 'David'],\n",
        "    'email': ['alice@mail.com', 'bob@mail.com', 'bob@mail.com', 'charlie@mail.com', 'david@mail.com', 'david@mail.com'],\n",
        "    'duplicate_col': ['Alice', 'Bob', 'Bob', 'Charlie', 'David', 'David']  # redundant with 'name'\n",
        "})\n",
        "\n",
        "# 1. Remove exact duplicate rows\n",
        "data_no_duplicates = data.drop_duplicates()\n",
        "\n",
        "# 2. Remove redundant columns (e.g., duplicate of 'name')\n",
        "data_no_redundancy = data_no_duplicates.loc[:, ~data_no_duplicates.T.duplicated()]\n",
        "\n",
        "# 3. Optional: Drop duplicates based on subset of columns (e.g., duplicate IDs)\n",
        "data_cleaned = data_no_redundancy.drop_duplicates(subset=['id'])\n",
        "\n",
        "print(data_cleaned)"
      ],
      "metadata": {
        "id": "KTvioylZ5eIQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}